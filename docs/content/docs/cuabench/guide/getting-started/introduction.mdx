---
title: Introduction
description: A benchmark to measure the capabilities of computer-use agents in desktop environments.
---

**Cua-Bench** is a framework and set of tasks for evaluating how well AI agents can accomplish complex tasks on a desktop computer using primarily the keyboard and mouse, or on a mobile device using primarily the touchscreen.

<div className="not-prose relative rounded-xl overflow-hidden my-8 w-full">
  <img src="/docs/img/cua_bench_screenshots.png" alt="Cua" className="w-full h-auto rounded-xl border" />
</div>

Examples of Cua-Bench tasks are:

- Navigating a web browser to book travel reservations
- Installing design software and editing images to remove backgrounds
- Using office applications to format and merge multiple documents

Cua-Bench consists of two parts:

1. **A dataset of tasks** - Verifiable, dynamic computer-use environments across multiple operating systems
2. **An evaluation/training harness** - Tools for running benchmarks, generating data, and testing agents

# Dataset of tasks

Each task in Cua-Bench includes:

- a description in English
- a config for the desktop/mobile environment
- a setup script to install any HTML webapps
- a test script to verify if the agent completed the task successfully
- a reference ("oracle") solution that solves the task

Check out our existing tasks [here](https://cuabench.ai/cuabench/registry)

# An environment harness

The harness provides familiar APIs for creating verifiable tasks. Use an Electron-like Python API to install web apps onto desktop/mobile environments, then use a Playwright-like API to write automated solutions or reward test scripts.

After [installing the package](/docs/cuabench/guide/getting-started/installation), you can run the harness using `cb run` or `cb interact`.

# Base Images

Cua-Bench uses **base images** - reproducible environments that provide consistent, isolated desktop or mobile VMs. Each image can be used to start sandboxes that can be stopped and reset to a known state.

| Type | Description | Requirements |
|------|-------------|--------------|
| `linux-docker` | Linux GUI container (XFCE) | Docker |
| `linux-qemu` | Linux VM with QEMU/KVM | Docker + KVM |
| `windows-qemu` | Windows 11 VM | Docker + KVM |
| `android-qemu` | Android VM | Docker + KVM |
| `macos-lume` | macOS VM via Lume | Apple Silicon |

See [Base Images](/docs/cuabench/guide/getting-started/images) for setup instructions.

# Supported Benchmarks

| Benchmark | Image | Tasks | Status | Description |
|-----------|--------------|-------|--------|-------------|
| Windows Arena | `windows-qemu` | 173 | Available | Windows 11 desktop automation across 12 apps |
| OSWorld | `linux-qemu` | 369 | Coming soon | Linux desktop automation |
| WebArena | `linux-docker` | 812 | Coming soon | Web browsing tasks |
| AndroidWorld | `android-qemu` | 200+ | Coming soon | Android mobile automation |
| macOSWorld | `macos-lume` | 100+ | Coming soon | macOS desktop automation |

# Next Steps

1. [Install the CLI](/docs/cuabench/guide/getting-started/installation)
2. [Create a base image](/docs/cuabench/guide/getting-started/images)
3. [Run your first benchmark](/docs/cuabench/guide/getting-started/first-steps)
4. [Create custom tasks](/docs/cuabench/guide/fundamentals/tasks)